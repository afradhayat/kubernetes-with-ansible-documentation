=====================================================================================================

                  DEPLOY A 1 MASTER 2 WORKER KUBERNETES CLUSTER USING ANSIBLE
 
====================================================================================================

PREREQUISITES: 

01. DOCKER ENGINE 

02. SSH-KEYGEN 

03. ANSIBLE 

====================================================================================================

SYSTEM INFORMATION: 

OS: CENTOS 7 
RAM: Master Node: 4 GB 
     Worker Node: 2 GB (Each) 
	 CPU: 2 Core minimum
	 
===================================================================================================

                            ANSIBLE INSTALLATION AT CENTOS 7

===================================================================================================
04. yum install python3 

05. yum install dnf 

06. dnf install epel-release

07. dnf install ansible 

====================================================================================================

								HOSTS FILE UPDATE IN BOTH NODES
								
====================================================================================================

08. vi /etc/hosts

127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
192.168.187.138 master
192.168.187.139 worker
192.168.187.140 worker 

09. Edit the hosts file in all three nodes for connectivity 


=====================================================================================================

									ESTABLISH THE SSH-KEYGEN

=====================================================================================================

10. ssh-keygen (master-node) 

11. ssh-copy-id root@192.168.187.138
    ssh-copy-id root@192.168.187.139
	ssh-copy-id root@192.168.187.140 

=======================================================================================================

          TEST THE ANSIBLE BY CALLING A PASSWORD LESS CONENCTIVITY BETWEEN NODES 

=======================================================================================================

12. ssh root@worker [IF THE CONNECTIVITY IS OK, THEN PROCEED
                     ELSE, CHECK YOUR SSH-KEYGEN ] 

=======================================================================================================

									ANSIBLE WORKING FILES

========================================================================================================

13. Create a "hosts" file by putting the environment IP's and hostnames, inside the ansible config folder


[kubernetes-master-nodes]
master ansible_host=192.168.187.138

[kubernetes-worker-nodes]
worker ansible_host=192.168.187.139
worker2 ansible_host=192.168.187.140
    

14. Create the "env_variable" file to set the environment parameter 

#Edit these values only as per your environment
#Enter your master node advertise ip address and cidr range for the pods.
ad_addr: 192.168.187.138
cidr_v: 10.244.0.0/16

###################################################################################
# Dont Edit these below values, these are mandatory to configure kubernetes cluster
packages:
- kubelet
- kubeadm
- kubectl


services:
- kubelet

###################################################################################

## Here, "ad_addr" is the master node ip and "cidr_v" is the pod network policy of weave-net

## packages states the packages which has to be downloaded later 

## services states the services which has to be enabled / disabled, in the later run 

------------------------------------------------------------------------------------------


15. Create the yml file to disable fstab in all nodes ----  " fstab.yml " 

---
- hosts: all
  vars_files:
  - env_variable
  tasks:
  - name: Disabling Swap on all nodes
    shell: swapoff -a

  - name: Commenting Swap entries in /etc/fstab
    replace:
     path: /etc/fstab
     regexp: '(.*swap*)'
     replace: '#\1'

============================================================================================
== ANSIBLE: create a yml file to start the ansible process at the ansible location 

vi commit.yml 

---
- import_playbook: playbooks/fstab.yml

Save and Exit

Execute the Command: ansible-playbook commit.yml 

Output: fstab is disabled in all nodes

==============================================================================================

16. Add firewalld rules for kubernetes service end points in all nodes 

firewall-cmd --permanent --add-port=6443/tcp 
firewall-cmd --permanent --add-port=10250/tcp


17. mkdir /etc/docker/


18. Crete a yml for letting ip tables to see bridged traffic ---- " ip_tables.yml "

---
- hosts: all
  vars_files:
  - env_variable
  tasks:
  - name: Letting ip tables see bridged traffic
    file:
     path: /etc/sysctl.d/k8s.conf
     state: touch

  - name: IP TABLES PARAMETER
    blockinfile:
     path: /etc/sysctl.d/k8s.conf
     block: |
      net.bridge.bridge-nf-call-ip6tables = 1 
	  net.bridge.bridge-nf-call-iptables = 1 


== ANSIBLE: create a yml file to start the ansible process at the ansible location 

vi commit_ip_tables.yml 

---
- import_playbook: playbooks/ip_tables.yml

Save and Exit

Execute the Command: ansible-playbook commit_ip_tables.yml 

Output: ip tables parameter is set at all nodes
==========================================================================================================================	  
	  
18. sysctl --system
	  
	  
	  
19. Set Selinux to enforcing mode, in all nodes: setenforce 0 
                                                 sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config
								   

20. sestatus 

==========================================================================================================================

												DOCKER INSTALLATION

==========================================================================================================================

21. Install yum utility: yum install -y yum-utils device-mapper-persistent-data lvm2  [in all nodes]

22. Add docker-ce-repo and install docker: yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo yum update -y && yum install containerd.io docker-ce docker-ce-cli   [ in all nodes ]

23. Create a yml file to set the docker daemon file

vi daemon-json.yml [inside the playbook] 

---
- hosts: all
  vars_files:
  - env_variable
  tasks:
  - name: Set the docker-daemon
    file:
     path: /etc/docker/daemon.json
     state: touch

  - name: IP TABLES PARAMETER
    blockinfile:
     path: /etc/docker/daemon.json
     block: |
       { "exec-opts": ["native.cgroupdriver=systemd"], 
	    "log-driver": "json-file", 
		"log-opts": { "max-size": "100m" }, 
		"storage-driver": "overlay2", 
		"storage-opts": [ "overlay2.override_kernel_check=true" ] 
		} 

SAVE AND EXIT 

== ANSIBLE: create a yml file to start the ansible process at the ansible location 

vi commit_daemon.yml 

---
- import_playbook: playbooks/daemon-json.yml

Save and Exit

Execute the Command: ansible-playbook commit_daemon.yml 

Output: docker-daemon is set at all nodes.

===========================================================================================================

24. mkdir -p /etc/systemd/system/docker.service.d  
    systemctl daemon-reload 
	systemctl restart docker
	systemctl enable docker

In all nodes. 


25. Installing kubeadm , kubectl, kubelet packages by ansible

Create a yml file inside playbook ==== 

vi kube-packages.yml 

---
- hosts: all
  vars_files:
  - env_variables
  tasks:
  - name: Creating a repository file for Kubernetes
    file:
     path: /etc/yum.repos.d/kubernetes.repo
     state: touch

  - name: Adding repository details in Kubernetes repo file.
    blockinfile:
     path: /etc/yum.repos.d/kubernetes.repo
     block: |
      [kubernetes]
      name=Kubernetes
      baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
      enabled=1
      gpgcheck=1
      repo_gpgcheck=1
      gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg
        https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg

  - name: Installing required packages
    yum:
     name: "{{ item }}"
     state: present
    with_items: "{{ packages }}"

  - name: Starting and Enabling the required services
    service:
     name: "{{ item }}"
     state: started
     enabled: yes
    with_items: "{{ services }}"


SAVE AND EXIT 

== ANSIBLE: create a yml file to start the ansible process at the ansible location 

vi commit_kube_packages.yml 

---
- import_playbook: playbooks/kube-packages.yml

Save and Exit

Execute the Command: ansible-playbook kube-packages.yml 

Output: Kubernetes packages are installed and enabled at the all nodes

===========================================================================================================

26. systemctl enable --now kubelet (Enable the kubelet) in all nodes. 


27. kubeadm init --pod-network-cidr 10.244.0.0/16 --apiserver-advertise-address=192.168.187.138 (At master node)

28. export KUBECONFIG=/etc/kubernetes/admin.conf     (for root user, execute this command) 

29. kubectl apply -f "https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\n')"

30. copy the token and join at the worker nodes. 



=============================================================================================================

                              KUBERNETES CLUSTER IS COMPLETED
							           @ afrad hayat
============================================================================================================



